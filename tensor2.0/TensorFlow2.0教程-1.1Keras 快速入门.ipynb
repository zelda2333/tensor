{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.构建简单模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.1模型堆叠**\n",
    "在 Keras 中，您可以通过组合层来构建模型。模型（通常）是由层构成的图。\n",
    "\n",
    "最常见的模型类型是层的堆叠：tf.keras.Sequential 模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "要构建一个简单的全连接网络（即多层感知器），请运行以下代码："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model = tf.keras.Sequential()\n",
    "# Adds a densely-connected layer with 64 units to the model:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Add another:\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# Add a softmax layer with 10 output units:\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.2网络配置**\n",
    "\n",
    "tf.keras.layers中网络配置：\n",
    "\n",
    "activation：设置层的激活函数。此参数由内置函数的名称指定，或指定为可调用对象。默认情况下，系统不会应用任何激活函数。\n",
    "\n",
    "kernel_initializer 和 bias_initializer：创建层权重（核和偏差）的初始化方案。此参数是一个名称或可调用对象，默认为 \"Glorot uniform\" 初始化器。\n",
    "\n",
    "kernel_regularizer 和 bias_regularizer：应用层权重（核和偏差）的正则化方案，例如 L1 或 L2 正则化。默认情况下，系统不会应用正则化函数。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用构造函数参数实例化 tf.keras.layers. Dense 层：\n",
    "\n",
    "**Create a sigmoid layer:**\n",
    "\n",
    "layers.Dense(32, activation='sigmoid')\n",
    "\n",
    "**OR**\n",
    "\n",
    "layers.Dense(32, activation=tf.sigmoid)\n",
    "\n",
    "**A linear layer with a kernel initialized to a random orthogonal matrix:**\n",
    "\n",
    "layers.Dense(32, kernel_initializer='orthogonal')\n",
    "\n",
    "**A linear layer with a bias vector initialized to 2.0s:**\n",
    "\n",
    "\n",
    "layers.Dense(64, bias_initializer=tf.keras.initializers.constant(2.0))\n",
    "\n",
    "\n",
    "**A linear layer with L2 regularization of factor 0.01 applied to the bias vector:**\n",
    "\n",
    "layers.Dense(32, kernel_regularizer=tf.keras.regularizers.l2(0.01))\n",
    "\n",
    "**A linear layer with L1 regularization of factor 0.01 applied to the kernel matrix:**\n",
    "\n",
    "layers.Dense(32, kernel_regularizer=tf.keras.regularizers.l1(0.01))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.训练和评估"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3.1设置训练流程**\n",
    "\n",
    "构建好模型后，通过调用 compile 方法配置该模型的学习流程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(optimizer=tf.train.AdamOptimizer(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras.Model.compile 采用三个重要参数：\n",
    "\n",
    "1. **optimizer(优化器)：**此对象会指定训练过程。从 tf.train 模块向其传递优化器实例，例如 tf.train.AdamOptimizer、tf.train.RMSPropOptimizer 或 tf.train.GradientDescentOptimizer。\n",
    "\n",
    "2. **loss(损失函数)：**要在优化期间最小化的函数。常见选择包括均方误差 (mse)、categorical_crossentropy 和 binary_crossentropy。损失函数由名称或通过从 tf.keras.losses 模块传递可调用对象来指定。\n",
    "\n",
    "3. **metrics：**用于监控训练。它们是 tf.keras.metrics 模块中的字符串名称或可调用对象。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#示例\n",
    "\n",
    "# Configure a model for mean-squared error regression.\n",
    "model.compile(optimizer=tf.train.AdamOptimizer(0.01),\n",
    "              loss='mse',       # mean squared error\n",
    "              metrics=['mae'])  # mean absolute error\n",
    "\n",
    "# Configure a model for categorical classification.\n",
    "model.compile(optimizer=tf.train.RMSPropOptimizer(0.01),\n",
    "              loss=tf.keras.losses.categorical_crossentropy,\n",
    "              metrics=[tf.keras.metrics.categorical_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2输入Numpy数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "对于小型数据集，请使用内存中的 NumPy 数组训练和评估模型。使用 fit 方法使模型与训练数据“拟合”："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0704 01:50:55.130002 139865602422528 deprecation.py:506] From /home/zelda/anaconda3/envs/flappbird/lib/python3.7/site-packages/tensorflow/python/training/rmsprop.py:119: calling Ones.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 200 samples\n",
      "Epoch 1/10\n",
      "1000/1000 [==============================] - 1s 531us/sample - loss: 11.8117 - categorical_accuracy: 0.1030 - val_loss: 11.5428 - val_categorical_accuracy: 0.1250\n",
      "Epoch 2/10\n",
      "1000/1000 [==============================] - 0s 53us/sample - loss: 12.7579 - categorical_accuracy: 0.1100 - val_loss: 13.4265 - val_categorical_accuracy: 0.1100\n",
      "Epoch 3/10\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 128.3592 - categorical_accuracy: 0.0910 - val_loss: 358.0298 - val_categorical_accuracy: 0.0700\n",
      "Epoch 4/10\n",
      "1000/1000 [==============================] - 0s 58us/sample - loss: 515.9449 - categorical_accuracy: 0.1190 - val_loss: 675.1303 - val_categorical_accuracy: 0.1300\n",
      "Epoch 5/10\n",
      "1000/1000 [==============================] - 0s 73us/sample - loss: 959.3281 - categorical_accuracy: 0.0960 - val_loss: 991.3003 - val_categorical_accuracy: 0.1300\n",
      "Epoch 6/10\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 1401.2798 - categorical_accuracy: 0.1040 - val_loss: 1511.2769 - val_categorical_accuracy: 0.0750\n",
      "Epoch 7/10\n",
      "1000/1000 [==============================] - 0s 64us/sample - loss: 1932.2359 - categorical_accuracy: 0.0970 - val_loss: 2485.9907 - val_categorical_accuracy: 0.0750\n",
      "Epoch 8/10\n",
      "1000/1000 [==============================] - 0s 68us/sample - loss: 2685.8392 - categorical_accuracy: 0.1050 - val_loss: 2297.4813 - val_categorical_accuracy: 0.1350\n",
      "Epoch 9/10\n",
      "1000/1000 [==============================] - 0s 73us/sample - loss: 3402.6984 - categorical_accuracy: 0.0960 - val_loss: 2854.8661 - val_categorical_accuracy: 0.1350\n",
      "Epoch 10/10\n",
      "1000/1000 [==============================] - 0s 60us/sample - loss: 4082.0707 - categorical_accuracy: 0.1030 - val_loss: 3012.4093 - val_categorical_accuracy: 0.1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f34a2deb710>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = np.random.random((1000, 72))\n",
    "train_y = np.random.random((1000, 10))\n",
    "\n",
    "val_x = np.random.random((200, 72))\n",
    "val_y = np.random.random((200, 10))\n",
    "\n",
    "model.fit(train_x, train_y, epochs=10, batch_size=100,\n",
    "          validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras.Model.fit 采用三个重要参数：\n",
    "\n",
    "1. **epochs：**以周期为单位进行训练。一个周期是对整个输入数据的一次迭代（以较小的批次完成迭代）。\n",
    "\n",
    "2. **batch_size：**当传递 NumPy 数据时，模型将数据分成较小的批次，并在训练期间迭代这些批次。此整数指定每个批次的大小。请注意，如果样本总数不能被批次大小整除，则最后一个批次可能更小。\n",
    "\n",
    "3. **validation_data：**在对模型进行原型设计时，您需要轻松监控该模型在某些验证数据上达到的效果。传递此参数（输入和标签元组）可以让该模型在每个周期结束时以推理模式显示所传递数据的损失和指标。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 tf.data输入数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用 Datasets API 可扩展为大型数据集或多设备训练。将 tf.data.Dataset 实例传递到 fit 方法："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0704 01:51:02.799634 139865602422528 training_utils.py:1300] Expected a shuffled dataset but input dataset `x` is not shuffled. Please invoke `shuffle()` on input dataset.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "30/30 [==============================] - 1s 24ms/step - loss: 6012.0614 - categorical_accuracy: 0.1031 - val_loss: 5428.7741 - val_categorical_accuracy: 0.1042\n",
      "Epoch 2/10\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 9068.6668 - categorical_accuracy: 0.1026 - val_loss: 11341.0247 - val_categorical_accuracy: 0.1146\n",
      "Epoch 3/10\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 12778.5560 - categorical_accuracy: 0.0897 - val_loss: 19284.1784 - val_categorical_accuracy: 0.1562\n",
      "Epoch 4/10\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 17422.1639 - categorical_accuracy: 0.0994 - val_loss: 19851.0501 - val_categorical_accuracy: 0.0521\n",
      "Epoch 5/10\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 21923.7078 - categorical_accuracy: 0.1111 - val_loss: 24601.4245 - val_categorical_accuracy: 0.1042\n",
      "Epoch 6/10\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 27247.8596 - categorical_accuracy: 0.1100 - val_loss: 28271.2708 - val_categorical_accuracy: 0.1042\n",
      "Epoch 7/10\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 34551.5405 - categorical_accuracy: 0.0940 - val_loss: 38984.8346 - val_categorical_accuracy: 0.1562\n",
      "Epoch 8/10\n",
      "30/30 [==============================] - 0s 8ms/step - loss: 40881.3326 - categorical_accuracy: 0.1047 - val_loss: 38338.2526 - val_categorical_accuracy: 0.1562\n",
      "Epoch 9/10\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 47887.0751 - categorical_accuracy: 0.0962 - val_loss: 51056.0260 - val_categorical_accuracy: 0.1146\n",
      "Epoch 10/10\n",
      "30/30 [==============================] - 0s 6ms/step - loss: 56620.5462 - categorical_accuracy: 0.1229 - val_loss: 53124.0195 - val_categorical_accuracy: 0.0833\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f34a2ae67b8>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#数据集也可用于验证：\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "dataset = dataset.batch(32)\n",
    "dataset = dataset.repeat()\n",
    "\n",
    "val_dataset = tf.data.Dataset.from_tensor_slices((val_x, val_y))\n",
    "val_dataset = val_dataset.batch(32)\n",
    "val_dataset = val_dataset.repeat()\n",
    "\n",
    "## Don't forget to specify `steps_per_epoch` when calling `fit` on a dataset.\n",
    "model.fit(dataset, epochs=10, steps_per_epoch=30,\n",
    "          validation_data=val_dataset, validation_steps=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在上方代码中，fit 方法使用了 steps_per_epoch 参数（表示模型在进入下一个周期之前运行的训练步数）。\n",
    "\n",
    "由于 Dataset 会生成批次数据，因此该代码段不需要 batch_size。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4评估与预测"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "tf.keras.Model.evaluate 和 tf.keras.Model.predict 方法可以使用 NumPy 数据和 tf.data.Dataset。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 0s 311us/sample - loss: 900.4741 - categorical_accuracy: 0.0850\n",
      "30/30 [==============================] - 0s 7ms/step - loss: 902.6332 - categorical_accuracy: 0.0865\n",
      "[[0.         0.20059122 0.07141831 ... 0.         0.         0.04704355]\n",
      " [0.         0.1335169  0.08730636 ... 0.         0.         0.05006244]\n",
      " [0.         0.11625621 0.11001544 ... 0.         0.         0.0657574 ]\n",
      " ...\n",
      " [0.         0.12437596 0.09429739 ... 0.         0.         0.02742871]\n",
      " [0.         0.09329625 0.16374002 ... 0.         0.         0.02834282]\n",
      " [0.         0.17811804 0.07292125 ... 0.         0.         0.04810395]]\n"
     ]
    }
   ],
   "source": [
    "test_x = np.random.random((1000, 72))\n",
    "test_y = np.random.random((1000, 10))\n",
    "model.evaluate(test_x, test_y, batch_size=32)\n",
    "\n",
    "test_data = tf.data.Dataset.from_tensor_slices((test_x, test_y))\n",
    "test_data = test_data.batch(32).repeat()\n",
    "model.evaluate(test_data, steps=30)\n",
    "# predict\n",
    "result = model.predict(test_x, batch_size=32)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 373us/sample - loss: 11.9665 - acc: 0.1050\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 179us/sample - loss: 17.4279 - acc: 0.1100\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 177us/sample - loss: 31.0557 - acc: 0.1040 - loss: 26.6764 - acc: 0.\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 159us/sample - loss: 52.0331 - acc: 0.1080\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 144us/sample - loss: 85.0141 - acc: 0.1030\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f34ac41ce10>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_x = tf.keras.Input(shape=(72,))\n",
    "hidden1 = tf.keras.layers.Dense(32, activation='relu')(input_x)\n",
    "hidden2 = tf.keras.layers.Dense(16, activation='relu')(hidden1)\n",
    "pred = tf.keras.layers.Dense(10, activation='softmax')(hidden2)\n",
    "\n",
    "model = tf.keras.Model(inputs=input_x, outputs=pred)\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "             loss=tf.keras.losses.categorical_crossentropy,\n",
    "             metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, batch_size=32, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 474us/sample - loss: 14.7737 - acc: 0.0890\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 264us/sample - loss: 19.8501 - acc: 0.0890\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 204us/sample - loss: 24.3473 - acc: 0.0960\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 244us/sample - loss: 29.1555 - acc: 0.0950\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 332us/sample - loss: 33.8304 - acc: 0.0890\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f34a6a2c438>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(MyModel, self).__init__(name='my_model')\n",
    "        self.num_classes = num_classes\n",
    "        self.layer1 = tf.keras.layers.Dense(32, activation='relu')\n",
    "        self.layer2 = tf.keras.layers.Dense(num_classes, activation='softmax')\n",
    "    def call(self, inputs):\n",
    "        h1 = self.layer1(inputs)\n",
    "        out = self.layer2(h1)\n",
    "        return out\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1] = self.num_classes\n",
    "        return tf.TensorShape(shape)\n",
    "\n",
    "model = MyModel(num_classes=10)\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "             loss=tf.keras.losses.categorical_crossentropy,\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y, batch_size=16, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0704 00:06:03.153837 139865602422528 deprecation.py:506] From /home/zelda/anaconda3/envs/flappbird/lib/python3.7/site-packages/tensorflow/python/keras/initializers.py:119: calling RandomUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 344us/sample - loss: 11.5246 - acc: 0.0890\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 289us/sample - loss: 11.5210 - acc: 0.0940\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 257us/sample - loss: 11.5175 - acc: 0.0900\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 333us/sample - loss: 11.5163 - acc: 0.0890\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 279us/sample - loss: 11.5147 - acc: 0.0930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f34a6e04320>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class MyLayer(tf.keras.layers.Layer):\n",
    "    def __init__(self, output_dim, **kwargs):\n",
    "        self.output_dim = output_dim\n",
    "        super(MyLayer, self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        shape = tf.TensorShape((input_shape[1], self.output_dim))\n",
    "        self.kernel = self.add_weight(name='kernel1', shape=shape,\n",
    "                                   initializer='uniform', trainable=True)\n",
    "        super(MyLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        return tf.matmul(inputs, self.kernel)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        shape = tf.TensorShape(input_shape).as_list()\n",
    "        shape[-1] = self.output_dim\n",
    "        return tf.TensorShape(shape)\n",
    "\n",
    "    def get_config(self):\n",
    "        base_config = super(MyLayer, self).get_config()\n",
    "        base_config['output_dim'] = self.output_dim\n",
    "        return base_config\n",
    "\n",
    "    @classmethod\n",
    "    def from_config(cls, config):\n",
    "        return cls(**config)\n",
    "\n",
    "model = tf.keras.Sequential(\n",
    "[\n",
    "    MyLayer(10),\n",
    "    tf.keras.layers.Activation('softmax')\n",
    "])\n",
    "\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "             loss=tf.keras.losses.categorical_crossentropy,\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_x, train_y, batch_size=16, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1000 samples, validate on 200 samples\n",
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 416us/sample - loss: 11.5128 - acc: 0.0930 - val_loss: 11.8113 - val_acc: 0.0950\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 193us/sample - loss: 11.5122 - acc: 0.0850 - val_loss: 11.8131 - val_acc: 0.0900\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 259us/sample - loss: 11.5114 - acc: 0.0900 - val_loss: 11.8110 - val_acc: 0.1000\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 310us/sample - loss: 11.5081 - acc: 0.0920 - val_loss: 11.8135 - val_acc: 0.0850\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 278us/sample - loss: 11.5067 - acc: 0.0960 - val_loss: 11.8126 - val_acc: 0.0900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f34ac138128>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(patience=2, monitor='val_loss'),\n",
    "    tf.keras.callbacks.TensorBoard(log_dir='./logs')\n",
    "]\n",
    "model.fit(train_x, train_y, batch_size=16, epochs=5,\n",
    "         callbacks=callbacks, validation_data=(val_x, val_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Weights for model sequential_2 have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1cda7b0c4d5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m               metrics=['accuracy'])\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./weights/model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./weights/model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flappbird/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36msave_weights\u001b[0;34m(self, filepath, overwrite, save_format)\u001b[0m\n\u001b[1;32m   1270\u001b[0m         \u001b[0mValueError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mFor\u001b[0m \u001b[0minvalid\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0munknown\u001b[0m \u001b[0mformat\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m     \"\"\"\n\u001b[0;32m-> 1272\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_assert_weights_created\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0mfilepath_is_h5\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_is_hdf5_filepath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msave_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/flappbird/lib/python3.7/site-packages/tensorflow/python/keras/engine/network.py\u001b[0m in \u001b[0;36m_assert_weights_created\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1671\u001b[0m                        \u001b[0;34m'Weights are created when the Model is first called on '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1672\u001b[0m                        \u001b[0;34m'inputs or `build()` is called with an `input_shape`.'\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1673\u001b[0;31m                        self.name)\n\u001b[0m\u001b[1;32m   1674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Weights for model sequential_2 have not yet been created. Weights are created when the Model is first called on inputs or `build()` is called with an `input_shape`."
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "tf.keras.layers.Dense(64, activation='relu'),\n",
    "tf.keras.layers.Dense(10, activation='softmax')])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.save_weights('./weights/model')\n",
    "model.load_weights('./weights/model')\n",
    "model.save_weights('./model.h5')\n",
    "model.load_weights('./model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1000/1000 [==============================] - 0s 465us/sample - loss: 11.4979 - acc: 0.0940\n",
      "Epoch 2/5\n",
      "1000/1000 [==============================] - 0s 158us/sample - loss: 11.4826 - acc: 0.0980\n",
      "Epoch 3/5\n",
      "1000/1000 [==============================] - 0s 157us/sample - loss: 11.5033 - acc: 0.1030\n",
      "Epoch 4/5\n",
      "1000/1000 [==============================] - 0s 142us/sample - loss: 11.5320 - acc: 0.1020\n",
      "Epoch 5/5\n",
      "1000/1000 [==============================] - 0s 150us/sample - loss: 11.5452 - acc: 0.1020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0704 00:35:07.352233 139865602422528 deprecation.py:506] From /home/zelda/anaconda3/envs/flappbird/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling GlorotUniform.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "W0704 00:35:07.360214 139865602422528 deprecation.py:506] From /home/zelda/anaconda3/envs/flappbird/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:97: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "  tf.keras.layers.Dense(10, activation='softmax', input_shape=(72,)),\n",
    "  tf.keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(train_x, train_y, batch_size=32, epochs=5)\n",
    "model.save('all_model.h5')\n",
    "model = tf.keras.models.load_model('all_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0704 00:37:26.978836 139865602422528 estimator.py:1811] Using temporary folder as model directory: /tmp/tmpwao6wkhq\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([tf.keras.layers.Dense(10,activation='softmax'),\n",
    "                          tf.keras.layers.Dense(10,activation='softmax')])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.RMSprop(0.001),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "estimator = tf.keras.estimator.model_to_estimator(model)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
